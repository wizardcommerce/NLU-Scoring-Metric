{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [CB-61] Metric and Testing Procedure Proposal for ChatBot NLU Tasks\n",
    "\n",
    "### Metric Formulation\n",
    "\n",
    "Our objective is to craft a metric that can be flexibly scaled and descaled depending on the constraints of the chatbot or chatbot component under development. Our metric needs to take into account expert knowledge of language phenomena in a way that can be used to qualify the confidence we should put on long-term model performance based on its known quirks. To those ends, the following metric can be used as part of a hard-test of model performance. Let $\\mathbb{S}$ be the score yielded in a Bayesian process, such that a model’s confidence based on any input $x$ ($P(I|x)$) is multiplied by a function that returns the average confidence that the model has when presented with utterances containing some linguistic phenomena $i$ ($f_i( \\cdot )$). Sentences that contain multiple phenomena (think: a sentence that has a long-distance dependency structure/lots of recursion, AND double negation) are multiplied times the joint probability of the average confidence for each phenomena present in the utterance. Let $\\lbrace^x \\cdot \\rbrace$ be the set of functions for linguistic phenomena $f_i$ that are present in input $x$.\n",
    "\n",
    "$$ \\mathbb{S}(I| \\lbrace^x f_i( \\cdot ) \\rbrace, x) \\propto P(I|x) \\prod_{i} f_i(x) $$\n",
    "\n",
    "This calculation has some useful properties.\n",
    "1. In cases where there is high confidence for a particular input x, but the phenomena in x typically cause the input to have lower confidence, this will check back the weight we put on an utterance like x as being emblematic of general model performance.\n",
    "    - In other words, this tells us if we’re just lucky that an input x gets high confidence from the model.\n",
    "2. This metric directly quantifies knowledge of model performance on myriad benchmark criteria from natural language usage and directly incorporates linguists’ real world knowledge and analyses.\n",
    "3. The list of phenomena studied ($\\lbrace^x f_i ( \\cdot ) \\rbrace$) can be modified on a case-by-case basis, excluding and including some phenomena as needed, based on expert or non-expert opinion.\n",
    "\n",
    "The score can then be used as a hard-check of model performance as follows: we expect$\\mathbb{S}$to be greater than chance if the model is more often than not confident for all the linguistic phenomena present in the utterance, and has high confidence for an intent $I$ based on an input $x$. We also expect the model to get the correct intent ($\\delta_{ I=\\textit{True}}$)\n",
    "\n",
    "$$ \\bigg( \\mathbb{S}( I | \\lbrace^x f_i( \\cdot ) \\rbrace,x ) > \\frac{1}{N_I} \\bigg) \\cdot \\bigg( \\delta_{I=\\textit{True}} \\bigg) $$\n",
    "\n",
    "Where $\\delta_{I=\\textit{True}}$ is a dirac-delta function that returns 1 if $I$ is the correct intent, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}